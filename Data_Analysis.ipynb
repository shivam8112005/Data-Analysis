{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import os\n",
    "import textwrap\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import mysql.connector\n",
    "import hashlib\n",
    "from sqlalchemy import create_engine\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"localhost\"\n",
    "DATABASE = \"data_analysis\"\n",
    "USER = \"root\"\n",
    "PASSWORD = \"\"\n",
    "def get_connection():\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=HOST,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            database=DATABASE\n",
    "        )\n",
    "        # print(\"Database Connected Successfully!\")\n",
    "        return conn\n",
    "    except mysql.connector.Error as e:\n",
    "        print(\"Database Connection Failed!\")\n",
    "        print(\"Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, uname, email, passw, num):\n",
    "       \n",
    "        self.uname=uname\n",
    "        self.email=email\n",
    "        self.passw=passw\n",
    "        if num==1:\n",
    "            self.id=self.savetodb( uname, email, passw)\n",
    "    def setId(self, id1):\n",
    "        self.id=id1\n",
    "    def setname(self, name):\n",
    "        self.uname=name\n",
    "    def setemail(self, email):\n",
    "        self.email=email\n",
    "    def setpass(self, passw):\n",
    "        self.passw=passw\n",
    "\n",
    "    def savetodb(self, uname, email, passw):\n",
    "         conn = get_connection()\n",
    "         if conn:\n",
    "            cursor = conn.cursor()\n",
    "            sql = \"INSERT INTO users (user_name, user_email, user_password) VALUES (%s, %s, %s)\"\n",
    "            password=self.hash_password(passw)\n",
    "            values = (uname, email, password)\n",
    "            cursor.execute(sql, values)\n",
    "            conn.commit()  \n",
    "            # print(\"User inserted successfully!\")\n",
    "            # cursor=conn.cursor()\n",
    "            sql= 'select user_Id from users where user_email= %s'\n",
    "            cursor.execute(sql, (email,))\n",
    "            id1=cursor.fetchone()\n",
    "            return id1[0]\n",
    "    def hash_password(self, password):\n",
    "        hashed = hashlib.sha256(password.encode()).hexdigest()\n",
    "        return hashed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Genreal_Report(corr_matrix, dup, head, tail, des, null, info, shape):\n",
    "   \n",
    "     try:\n",
    "        folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        report = os.path.join(folder_path, \"report.txt\")\n",
    "        heatmap_file = os.path.join(folder_path, \"correlation_heatmap.png\")\n",
    "       \n",
    "\n",
    "        rows, cols = corr_matrix.shape\n",
    "        max_label_length = max(len(label) for label in corr_matrix.columns)\n",
    "\n",
    "        fig_width = max(8, cols * 0.5, max_label_length * 0.5)\n",
    "        fig_height = max(6, rows * 0.5)\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(cols), corr_matrix.columns, rotation=45, ha=\"right\", fontsize=12)\n",
    "        plt.yticks(np.arange(rows), corr_matrix.columns, rotation=0, fontsize=12)\n",
    "        plt.title('Correlation Matrix Heatmap', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(heatmap_file)  \n",
    "        plt.close()\n",
    "        with open(report, 'w') as f:\n",
    "            f.write(\"GENERAL ANALYSIS OF THE DATAFRAME\\n\")\n",
    "            f.write(\"*\" * 50 + \"\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(f\"Shape of DataFrame: {shape}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Column Information:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(info) + \"\\n\") \n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Missing Values in Each Column:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(null) + \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Descriptive Statistics (Numerical):\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            # f.write(str(des) + \"\\n\")\n",
    "            f.write(tabulate(des, headers='keys', tablefmt='psql')+ \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"First 5 Rows of the DataFrame:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            # f.write(str(head) + \"\\n\")\n",
    "            f.write(tabulate(head, headers='keys', tablefmt='psql')+ \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Last 5 Rows of the DataFrame:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(tabulate(tail, headers='keys', tablefmt='psql')+ \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(f\"Number of Duplicate Rows: {dup}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Correlation Matrix (Numerical Columns):\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(tabulate(corr_matrix, headers='keys', tablefmt='psql')+ \"\\n\")\n",
    "            f.write(\"\\n\\n\")\n",
    "        \n",
    "        print(f\"Report successfully saved as '{report}'.\")\n",
    "     except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def General_Analysis(df):\n",
    "\n",
    "    null_values=df.isnull().sum()\n",
    "    dup = df.duplicated().sum()\n",
    "\n",
    "    # Data Cleaning\n",
    "    missing_values=df.isnull().sum()\n",
    "    missing_columns=missing_values[missing_values>0].index.tolist()\n",
    "    \n",
    "    for col in missing_columns:\n",
    "        if df[col].dtype=='object':\n",
    "            df[col]=df[col].fillna(df[col].mode()[0])\n",
    "        else: \n",
    "            if df[col].dropna().shape[0] > 0:  \n",
    "                df[col] = df[col].fillna(df[col].median())  \n",
    "            else:\n",
    "                df[col] = df[col].fillna(0)  \n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERAL ANALYSIS OF THE DATAFRAME\".center(60))\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 200)\n",
    "    shape = df.shape\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Shape of DataFrame: {shape}\")\n",
    "    print(\"-\" * 60 + \"\\n\")\n",
    "    print(\"COLUMN INFORMATION\".center(60, \"-\"))\n",
    "    buffer = StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info = buffer.getvalue()\n",
    "    print(info)\n",
    "    print(\"\\n\")\n",
    "    print(\"MISSING VALUES IN EACH COLUMN\".center(60, \"-\"))\n",
    "   \n",
    "    print(null_values)\n",
    "    print(\"\\n\")\n",
    "    numdf = df.select_dtypes(include=['number']).fillna(0)\n",
    "    print(\"DESCRIPTIVE STATISTICS (NUMERICAL)\".center(60, \"-\"))\n",
    "    des = numdf.describe()\n",
    "    print(tabulate(des, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"FIRST 5 ROWS OF THE DATAFRAME\".center(60, \"-\"))\n",
    "    head = df.head()\n",
    "    print(tabulate(head, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"LAST 5 ROWS OF THE DATAFRAME\".center(60, \"-\"))\n",
    "    tail = df.tail()\n",
    "    print(tabulate(tail, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"DUPLICATE ROWS\".center(60, \"-\"))\n",
    "    \n",
    "    print(f\"Number of Duplicate Rows: {dup}\")\n",
    "    print(\"\\n\")\n",
    "    if not numdf.empty:\n",
    "        print(\"CORRELATION MATRIX (NUMERICAL COLUMNS)\".center(60, \"-\"))\n",
    "        corr_matrix = numdf.corr()\n",
    "        print(tabulate(corr_matrix, headers='keys', tablefmt='psql'))\n",
    "        print(\"\\n\")\n",
    "        rows, cols = corr_matrix.shape\n",
    "        max_label_length = max(len(label) for label in corr_matrix.columns)\n",
    "        fig_width = max(8, cols * 0.5, max_label_length * 0.5)\n",
    "        fig_height = max(6, rows * 0.5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(cols), corr_matrix.columns, rotation=45, ha=\"right\", fontsize=12)\n",
    "        plt.yticks(np.arange(rows), corr_matrix.columns, rotation=0, fontsize=12)\n",
    "        plt.title('Correlation Matrix Heatmap', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\" No Nmerical Column in DF !!!!\")\n",
    "\n",
    "    save = input('Save General Report? (Y/N): ')\n",
    "    if save.lower()==\"y\":\n",
    "        sys.stdout.flush()\n",
    "        Save_Genreal_Report(corr_matrix, dup, head, tail, des, null_values, info, shape)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_custom(df, col1, col2):\n",
    "    col_names = {col.lower(): col for col in df.columns}\n",
    "    col1_actual = col_names.get(col1.lower())\n",
    "    col2_actual = col_names.get(col2.lower())\n",
    "\n",
    "    if not col1_actual or not col2_actual:\n",
    "        print(f\"❌ Error: One or both columns '{col1}' or '{col2}' not found in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(df[col1_actual]) or not pd.api.types.is_numeric_dtype(df[col2_actual]):\n",
    "        print(f\"❌ Error: One or both selected columns are not numeric.\")\n",
    "        return\n",
    "\n",
    "    df[col1_actual] = pd.to_numeric(df[col1_actual], errors='coerce')\n",
    "    df[col2_actual] = pd.to_numeric(df[col2_actual], errors='coerce')\n",
    "    df.dropna(inplace=True)  \n",
    "\n",
    "    # Generate report text\n",
    "    report_lines = [\n",
    "        \"=============================== Preview ================================\\n\",\n",
    "        f\"Data for {col1_actual}:\\n{tabulate(df[col1_actual].head().to_frame(), headers='keys', tablefmt='psql')}\\n\",\n",
    "        f\"Data for {col2_actual}:\\n{tabulate(df[col2_actual].head().to_frame(), headers='keys', tablefmt='psql')}\\n\",\n",
    "        f\"================================ Summary Statistics for {col1_actual} ======================================\\n\",\n",
    "        tabulate(df[col1_actual].describe().to_frame().reset_index(), headers=['Statistic', col1_actual], tablefmt='psql') + \"\\n\",\n",
    "        f\"================================ Summary Statistics for {col2_actual} ======================================\\n\",\n",
    "        tabulate(df[col2_actual].describe().to_frame().reset_index(), headers=['Statistic', col2_actual], tablefmt='psql') + \"\\n\",\n",
    "        f\"Correlation between {col1_actual} and {col2_actual}: {df[col1_actual].corr(df[col2_actual])}\\n\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "    jitter_x = np.random.normal(0, (df[col1_actual].max() - df[col1_actual].min()) * 0.02, size=len(df[col1_actual]))\n",
    "    jitter_y = np.random.normal(0, (df[col2_actual].max() - df[col2_actual].min()) * 0.02, size=len(df[col2_actual]))\n",
    "\n",
    "    plt.scatter(df[col1_actual] + jitter_x, df[col2_actual] + jitter_y, alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Scatter Plot with Jitter\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(df.index, df[col2_actual].rolling(window=500, min_periods=1).mean(), linestyle='-')\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Line Plot\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(df[col1_actual], bins=30, alpha=0.7, density=True, color='blue', label=col1_actual)\n",
    "    plt.hist(df[col2_actual], bins=30, alpha=0.7, density=True, color='red', label=col2_actual)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Histogram\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(df[[col1_actual, col2_actual]].corr(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.yticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    new_folder_path = os.path.join(folder_path, \"report.txt\")\n",
    "   \n",
    "    \n",
    "    \n",
    "    with open(new_folder_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(report_lines)\n",
    "\n",
    "    visualization_file = os.path.join(folder_path, \"visualization.png\")\n",
    "    plt.savefig(visualization_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Report saved at: {new_folder_path}\")\n",
    "    print(f\"✅ Visualization saved at: {visualization_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_Analysis(df, col1, col2, num):\n",
    "    col_names = {col.lower(): col for col in df.columns}\n",
    "    col1_actual = col_names.get(col1.lower())\n",
    "    col2_actual = col_names.get(col2.lower())\n",
    "    if not col1_actual or not col2_actual:\n",
    "        print(f\"❌ Error: One or both columns '{col1}' or '{col2}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[col1_actual]):\n",
    "        print(f\"❌ Error: Column '{col1_actual}' is not numeric.\")\n",
    "        return\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[col2_actual]):\n",
    "        print(f\"❌ Error: Column '{col2_actual}' is not numeric.\")\n",
    "        return\n",
    "    \n",
    "    if(df[col1].isna().all() or (df[col1]==\"\").all()):\n",
    "        print(f'column {col1} is completely Empty !')\n",
    "        return\n",
    "    if(df[col2].isna().all() or (df[col2]==\"\").all()):\n",
    "        print(f'column {col2} is completely Empty !')\n",
    "\n",
    "    # print(df[col1_actual], \"hello -1\")\n",
    "    # print(df[col2_actual], \"hello 0\")\n",
    "    df[col1_actual] = pd.to_numeric(df[col1_actual], errors='coerce')\n",
    "    df[col2_actual] = pd.to_numeric(df[col2_actual], errors='coerce')\n",
    "    \n",
    "    # this wont work in diwali sales cause status and unamed are totally empty so it will delete all rows\n",
    "    # df.dropna(inplace=True)  \n",
    "\n",
    "    column1_data=df[col1_actual]\n",
    "    column2_data=df[col2_actual]\n",
    "    null_count_col1 = column1_data.isnull().sum()\n",
    "    null_count_col2 = column2_data.isnull().sum()\n",
    "\n",
    "    # Data Cleaning\n",
    "    column1_data = column1_data.dropna()\n",
    "    column2_data = column2_data.dropna()\n",
    "    # print(df[col1_actual], \"hello 0.25\")\n",
    "    # print(df[col2_actual], \"hello 0.35\")\n",
    "    # print(column1_data, \"hello 0.5\")\n",
    "    # print(column2_data, \"hello 0.75\")\n",
    "    \n",
    "    # print(column1_data, \" hello 0\")\n",
    "    # print(column2_data, \" hello 1\")\n",
    "    print(\"=============================== Preview ================================\")\n",
    "    column1_data_df = column1_data.head().to_frame()\n",
    "    column2_data_df = column2_data.head().to_frame()\n",
    "    # print(column1_data_df, \"hello 1\")\n",
    "    # print(column2_data_df, \"hello 2\")\n",
    "    print(f\"Data for {col1_actual}:\\n\", tabulate(column1_data_df, headers='keys', tablefmt='psql'), \"\\n\")\n",
    "    print(f\"Data for {col2_actual}:\\n\", tabulate(column2_data_df, headers='keys', tablefmt='psql'), \"\\n\")\n",
    "    print(f\"================================ Summary Statistics for {col1_actual} ======================================\")\n",
    "    column1_stats = column1_data.describe()\n",
    "\n",
    "    column1_stats_df = column1_stats.to_frame().reset_index()\n",
    "    print(tabulate(column1_stats_df, headers=['Statistic', col1_actual], tablefmt='psql'), \"\\n\")\n",
    "    \n",
    "    print(f\"====================================== Summary Statistics for {col2_actual} ========================================\")\n",
    "    column2_stats = column2_data.describe()\n",
    "\n",
    "    column2_stats_df = column2_stats.to_frame().reset_index()\n",
    "    print(tabulate(column2_stats_df, headers=['Statistic', col2_actual], tablefmt='psql'), \"\\n\")\n",
    "    # print(column2_data.describe(), \"\\n\")\n",
    "    \n",
    "    print(f\"Null values in {col1_actual}: {null_count_col1}\")\n",
    "    # print(f\"Empty values in {col1_actual}: {empty_count_col1}\\n\")\n",
    "    \n",
    "    print(f\"Null values in {col2_actual}: {null_count_col2}\")\n",
    "    # print(f\"Empty values in {col2_actual}: {empty_count_col2}\\n\")\n",
    "    correlation = column1_data.corr(column2_data)\n",
    "    print(f\"Correlation between {col1_actual} and {col2_actual}: {correlation}\\n\")\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "   \n",
    "    \n",
    "   \n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # jitter_x = np.random.normal(0, (df[col1_actual].max() - df[col1_actual].min()) * 0.02, size=len(df[col1_actual]))\n",
    "    # jitter_y = np.random.normal(0, (df[col2_actual].max() - df[col2_actual].min()) * 0.02, size=len(df[col2_actual]))\n",
    "\n",
    "    # plt.scatter(df[col1_actual] + jitter_x,df[col2_actual] + jitter_y, c='red', alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    # plt.scatter(df[col2_actual] + jitter_x,df[col1_actual] + jitter_y, c='blue', alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    jitter_x = np.random.normal(0, (df[col1_actual].max() - df[col1_actual].min()) * 0.02, size=len(df[col1_actual]))\n",
    "    jitter_y = np.random.normal(0, (df[col2_actual].max() - df[col2_actual].min()) * 0.02, size=len(df[col2_actual]))\n",
    "\n",
    "    plt.scatter(df[col1_actual] + jitter_x, df[col2_actual] + jitter_y, alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Scatter Plot with Jitter\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "\n",
    "    rolling_window = 500  \n",
    "    df['RollingMean'] = df[col2_actual].rolling(window=rolling_window, min_periods=1).mean()\n",
    "\n",
    "    plt.plot(df.index, df['RollingMean'], linestyle='-')\n",
    "\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(f\"Line Plot (Smoothed, Window={rolling_window})\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)  \n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(df[col1_actual], bins=30, alpha=0.7, density=True, color='darkblue', label=col1_actual)  \n",
    "    plt.hist(df[col2_actual], bins=30, alpha=0.7, density=True, color='darkred', label=col2_actual)  \n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Histogram (Optimized)\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    corr_matrix = df[[col1_actual, col2_actual]].corr()\n",
    "    plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], [col1_actual, col2_actual], rotation=45)\n",
    "    plt.yticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    save=input(\"Do you want to save this report ?\")\n",
    "    if(save.lower()==\"y\"):\n",
    "        save_custom(df, col1, col2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_string_report(df, column_name, output_folder=\"output\", top_n=10):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    # os.makedirs(output_folder, exist_ok=True)  \n",
    "    # report_path = os.path.join(output_folder, f\"{column_name}_report.txt\")  \n",
    "    # img_path = os.path.join(output_folder, f\"{column_name}_visualization.png\")  \n",
    "\n",
    "    \n",
    "    value_counts = Counter(df[column_name].dropna())\n",
    "\n",
    "    if len(value_counts) > top_n:\n",
    "        most_common = dict(value_counts.most_common(top_n))\n",
    "        others_count = sum(count for key, count in value_counts.items() if key not in most_common)\n",
    "        most_common[\"Others\"] = others_count\n",
    "        value_counts = most_common\n",
    "\n",
    "    labels = list(value_counts.keys())\n",
    "    counts = list(value_counts.values())\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(labels, counts, color='darkblue')\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {column_name} (Top {top_n} Categories)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors,\n",
    "        startangle=90, labeldistance=1.2, pctdistance=0.8,\n",
    "        textprops={'rotation_mode': 'anchor', 'fontsize': 10})\n",
    "    plt.title(f\"Distribution of {column_name} (Pie Chart)\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    text = \" \".join(df[column_name].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Word Cloud for {column_name}\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    heatmap_data = np.array(counts).reshape(1, -1)\n",
    "    plt.imshow(heatmap_data, aspect='auto', cmap='Blues')\n",
    "    plt.colorbar(label=\"Count\")\n",
    "    plt.title(f\"Heatmap for {column_name}\")\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels, rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(img_path)  \n",
    "    \n",
    "\n",
    "\n",
    "    folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    new_folder_path = os.path.join(folder_path, \"report.txt\")\n",
    "\n",
    "    with open(new_folder_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Report for Column: {column_name}\\n\")\n",
    "        file.write(\"=\" * 40 + \"\\n\\n\")\n",
    "        file.write(f\"Total Unique Values: {len(value_counts)}\\n\")\n",
    "        file.write(\"\\nTop Occurring Values:\\n\")\n",
    "\n",
    "        for label, count in zip(labels, counts):\n",
    "            file.write(f\"{label}: {count}\\n\")\n",
    "\n",
    "        # file.write(\"\\nVisualization saved at: \" + img_path + \"\\n\")\n",
    "    visualization_file = os.path.join(folder_path, \"visualization.png\")\n",
    "    plt.savefig(visualization_file)\n",
    "    plt.close()\n",
    "    print(f\"Report saved: {new_folder_path}\")\n",
    "    print(f\"Visualization saved: {visualization_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_string_column(df, column_name, top_n=10):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    value_counts = Counter(df[column_name].dropna())  \n",
    "\n",
    "    if len(value_counts) > top_n:\n",
    "        most_common = dict(value_counts.most_common(top_n))\n",
    "        others_count = sum(count for _, count in value_counts.items() if _ not in most_common)\n",
    "        most_common[\"Others\"] = others_count\n",
    "        \n",
    "        value_counts = most_common\n",
    "\n",
    "    labels = list(value_counts.keys())\n",
    "    counts = list(value_counts.values())\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)  \n",
    "    plt.bar(labels, counts, color='darkblue')\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {column_name} (Top {top_n} Categories)\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    plt.subplot(2, 2, 2)  \n",
    "    # plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors)\n",
    "    # plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors,\n",
    "    #     labeldistance=1.1, pctdistance=0.85, textprops={'fontsize': 10},\n",
    "    #     wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors,\n",
    "        startangle=90, labeldistance=1.2, pctdistance=0.8,\n",
    "        textprops={'rotation_mode': 'anchor', 'fontsize': 10})\n",
    "    plt.title(f\"Distribution of {column_name} (Pie Chart)\")\n",
    "\n",
    "    \n",
    "    plt.subplot(2, 2, 3)  \n",
    "    if df[column_name].dtype == 'object':  \n",
    "        text = \" \".join(df[column_name].dropna())\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Word Cloud for {column_name}\")\n",
    "    else:\n",
    "        plt.axis('off')  \n",
    "    plt.subplot(2, 2, 4) \n",
    "   \n",
    "    heatmap_data = np.array(counts).reshape(1, -1) \n",
    "    plt.imshow(heatmap_data, aspect='auto', cmap='Blues')\n",
    "    plt.colorbar(label=\"Count\")\n",
    "    plt.title(f\"Heatmap for {column_name}\")\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels, rotation=90)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Basic Analysis\n",
    "    print(f\"\\n====================================== Basic Analysis of '{column_name}' ===========================================\")\n",
    "    print(f\"Total unique values (Top {top_n} with 'Others'): {len(value_counts)}\")\n",
    "    for label, count in value_counts.items():\n",
    "        print(f\"{label}: {count} occurrences\")\n",
    "    # print(f\"Total Number of Unique Values in {column_name}: \", )\n",
    "    choice=input(\"want to save this repiort (y/n) ?\")\n",
    "    if(choice.lower()=='y'):\n",
    "        sys.stdout.flush()\n",
    "        save_string_report(df, column_name, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Data(df):\n",
    "    b=True\n",
    "    while(b):\n",
    "        print(\"Analyze Data\".center(60, \"*\"))\n",
    "        print(\"1. General Analysis\")\n",
    "        print(\"2. Custom Analysis\")\n",
    "        print(\"3. Return\")\n",
    "        sys.stdout.flush()\n",
    "        choice=input(\"Enter Choice: \").strip()\n",
    "        if(choice==\"1\"):\n",
    "           print(\"General Analysis\".center(60, \"*\"))\n",
    "           sys.stdout.flush()\n",
    "           General_Analysis(df)\n",
    "        elif(choice==\"2\"):\n",
    "            b1=True\n",
    "            while(b1):\n",
    "                print(\"Custom Analysis\".center(60, \"*\"))\n",
    "                print(\"1. Categorical Exploration\")\n",
    "                print(\"2. Analyze Two Numeric Columns\")\n",
    "                print(\"3. Return\")\n",
    "                sys.stdout.flush()\n",
    "                choice=input(\"Enter Choice: \").strip()\n",
    "                if(choice==\"2\"):\n",
    "                  col1=input('Enter 1st Numeric Column')\n",
    "                  col2=input('Enter 2nd Numeric Column')\n",
    "                  sys.stdout.flush()\n",
    "                  Custom_Analysis(df, col1, col2, 1)\n",
    "                  \n",
    "                elif(choice==\"1\"):\n",
    "                    # col1=input('Enter 1st Numeric Column')\n",
    "                    col2=input('Enter String Column')\n",
    "                    sys.stdout.flush()\n",
    "                    plot_string_column(df, col2)\n",
    "                elif(choice==\"3\"):\n",
    "                  b1=False\n",
    "                else:\n",
    "                  print(\"Please Enter Valid Choice !\")\n",
    "        elif(choice==\"3\"):\n",
    "          # print(\"Exiting Program...\")\n",
    "          b=False\n",
    "        else:\n",
    "          print(\"Please Enter Valid Choice !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Data():\n",
    "    b=True\n",
    "    while(b):\n",
    "        print(\"Load Data\".center(60, \"*\"))\n",
    "        print(\"1. Load CSV File\")\n",
    "        print(\"2. Load SQL Table\")\n",
    "        print(\"3. Load Parquet File\")\n",
    "        print(\"4. Load Excel File\")\n",
    "        print(\"5. Return\")\n",
    "        sys.stdout.flush()\n",
    "        choice=input(\"Enter Choice: \").strip()\n",
    "        if(choice==\"1\"):\n",
    "          path = input(\"Enter File Path of CSV File: \")\n",
    "          try:\n",
    "              df = pd.read_csv(path, encoding='unicode_escape')\n",
    "              return df\n",
    "          except (FileNotFoundError, Exception) as e:\n",
    "              print(f\"Error: {e}\")\n",
    "            #   print(\"CSV File not found. Try again !\")\n",
    "               \n",
    "        elif(choice==\"2\"):\n",
    "              table = input(\"Enter Table name: \")\n",
    "              try:\n",
    "                  conn=get_connection()\n",
    "                  sql=f'select * from {table}'\n",
    "                  engine = create_engine(\"mysql+pymysql://root:@localhost/data_analysis\")\n",
    "                  df = pd.read_sql(sql, con=engine)\n",
    "                  df = pd.read_sql(sql, conn)\n",
    "                  return df\n",
    "              except (FileNotFoundError, Exception) as e:\n",
    "                  print(f\"Error: {e}\")\n",
    "                  print(\"Table not found. Try again !\")\n",
    "        elif(choice==\"3\"):\n",
    "              path = input(\"Enter File Path of Parquet File: \")\n",
    "              try:\n",
    "                  df = pd.read_parquet(path)\n",
    "                  return df\n",
    "              except (FileNotFoundError, Exception) as e:\n",
    "                  print(f\"Error: {e}\")\n",
    "                  print(\"Parquet File not found. Try again !\")\n",
    "        elif(choice==\"4\"):\n",
    "              path = input(\"Enter File Path of Excel File: \")\n",
    "              try:\n",
    "                  df = pd.read_excel(path)\n",
    "                  return df\n",
    "              except (FileNotFoundError, Exception) as e:\n",
    "                  print(f\"Error: {e}\")\n",
    "                  print(\"Excel File not found. Try again !\")\n",
    "        elif(choice==\"5\"):\n",
    "          # print(\"Exiting Program...\")\n",
    "          b=False\n",
    "        else:\n",
    "          print(\"Please Enter Valid Choice !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(df):\n",
    "    \"\"\"Saves the dataset to a user-specified path.\"\"\"\n",
    "    b=True\n",
    "    while b:\n",
    "        print(\"Save DataSet\".center(60, \"*\"))\n",
    "        print(\"1. Save as CSV\")\n",
    "        print(\"2. Save as Table in MySQL\")\n",
    "        print(\"3. Exit\")\n",
    "        sys.stdout.flush()\n",
    "        ch=input('Enter your choice: ')\n",
    "        if(ch=='1'):\n",
    "            save_path = input(\"Enter the path to save the edited CSV file: \")\n",
    "            try:\n",
    "                df.to_csv(save_path, index=False)\n",
    "                print(f\"\\nDataset saved successfully at {save_path}!\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error in saving a dataset as CSV: {e}\")\n",
    "        elif ch=='2':\n",
    "            try:\n",
    "                name=input('Enter name of the table to save DataFrame as: ')\n",
    "                engine = create_engine(\"mysql+pymysql://root:@localhost/data_analysis\")\n",
    "                df.to_sql(name, con=engine, if_exists=\"replace\", index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in saving a dataset as Table: {e}\")\n",
    "        elif ch=='3':\n",
    "            b=False\n",
    "        else:\n",
    "            print('Invalid Choice !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edit_Data(df):\n",
    "    b = True\n",
    "    while b:\n",
    "        print(\"Edit Data\".center(60, \"*\"))\n",
    "        print(\"1. Add a New Row\")\n",
    "        print(\"2. Update an Existing Row\")\n",
    "        print(\"3. Delete a Row\")\n",
    "        print(\"4. Edit Specific Column Data\")\n",
    "        # print(\"5. Fill Missing Data\")\n",
    "        print(\"5. Rename Columns\")\n",
    "        print(\"6. Change Data Type of a Column\")\n",
    "        print(\"7. Sort Data\")\n",
    "        print(\"8. Filter Data\")\n",
    "        print(\"9. Remove Duplicates\")\n",
    "        print(\"10. Save and Return\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        choice = input(\"Enter Choice: \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            print(\"\\nAdding a new row:\")\n",
    "            new_row = {}\n",
    "            for col in df.columns:\n",
    "                new_row[col] = input(f\"Enter value for {col}: \")\n",
    "            df.loc[len(df)] = new_row \n",
    "            print(\"\\nRow added successfully!\")\n",
    "        elif choice == \"2\":\n",
    "            print(\"\\nUpdating an existing row:\")\n",
    "            row_index = int(input(\"Enter row index to update: \"))\n",
    "            if 0 <= row_index < len(df):\n",
    "                col_name = input(\"Enter column name to update: \")\n",
    "                new_value = input(\"Enter new value: \")\n",
    "                df.at[row_index, col_name] = new_value\n",
    "                print(\"\\nRow updated successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid row index!\")\n",
    "        elif choice == \"3\":\n",
    "            print(\"\\nDeleting a row:\")\n",
    "            row_index = int(input(\"Enter row index to delete: \"))\n",
    "            if 0 <= row_index < len(df):\n",
    "                df = df.drop(index=row_index).reset_index(drop=True)\n",
    "                print(\"\\nRow deleted successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid row index!\")\n",
    "        elif choice == \"4\":\n",
    "            print(\"\\nEditing specific column data:\")\n",
    "            col_name = input(\"Enter column name: \")\n",
    "            if col_name in df.columns:\n",
    "                df[col_name] = df[col_name].apply(lambda x: input(f\"Enter new value for {x}: \"))\n",
    "                print(\"\\nColumn updated successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid column name!\")\n",
    "        # elif choice == \"5\":\n",
    "        #     print(\"\\nFilling missing data:\")\n",
    "        #     fill_method = input(\"Enter 'mean', 'median', 'mode', or a specific value: \")\n",
    "        #     if fill_method == \"mean\":\n",
    "        #         df.fillna(df.mean(), inplace=True)\n",
    "        #     elif fill_method == \"median\":\n",
    "        #         df.fillna(df.median(), inplace=True)\n",
    "        #     elif fill_method == \"mode\":\n",
    "        #         df.fillna(df.mode().iloc[0], inplace=True)\n",
    "        #     else:\n",
    "        #         df.fillna(fill_method, inplace=True)\n",
    "        #     print(\"\\nMissing values filled successfully!\")\n",
    "        elif choice == \"5\":\n",
    "            print(\"\\nRenaming columns:\")\n",
    "            print(\"Current columns:\", list(df.columns))\n",
    "            old_col = input(\"Enter the column name to rename: \")\n",
    "            new_col = input(\"Enter the new column name: \")\n",
    "            df.rename(columns={old_col: new_col}, inplace=True)\n",
    "            print(\"\\nColumn renamed successfully!\")\n",
    "        elif choice == \"6\":\n",
    "            print(\"\\nChanging data type of a column:\")\n",
    "            col_name = input(\"Enter column name: \")\n",
    "            new_type = input(\"Enter new data type (int, float, str): \")\n",
    "            try:\n",
    "                if new_type == \"int\":\n",
    "                    df[col_name] = df[col_name].astype(int)\n",
    "                elif new_type == \"float\":\n",
    "                    df[col_name] = df[col_name].astype(float)\n",
    "                elif new_type == \"str\":\n",
    "                    df[col_name] = df[col_name].astype(str)\n",
    "                print(\"\\nData type changed successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error changing data type: {e}\")\n",
    "        elif choice == \"7\":\n",
    "            print(\"\\nSorting data:\")\n",
    "            col_name = input(\"Enter column name to sort by: \")\n",
    "            order = input(\"Enter 'asc' for ascending or 'desc' for descending: \")\n",
    "            df = df.sort_values(by=col_name, ascending=(order == \"asc\"))\n",
    "            print(\"\\nData sorted successfully!\")\n",
    "        elif choice == \"8\":\n",
    "           print(\"\\nFiltering data:\")\n",
    "           col_name = input(\"Enter column name to filter by: \")\n",
    "\n",
    "            # Check if column exists\n",
    "           if col_name not in df.columns:\n",
    "                print(\"Error: Column does not exist!\")\n",
    "           else:\n",
    "                print(\"\\nChoose filter type:\")\n",
    "                print(\"1. Equal to (==)\")\n",
    "                print(\"2. Greater than (>)\")\n",
    "                print(\"3. Smaller than (<)\")\n",
    "                sys.stdout.flush()\n",
    "                filter_type = input(\"Enter choice (1/2/3): \")\n",
    "\n",
    "                filter_value = input(f\"Enter value to filter {col_name} by: \")\n",
    "\n",
    "                try:\n",
    "                    # Convert filter_value to correct type (int/float if possible)\n",
    "                    if df[col_name].dtype in ['int64', 'float64']:  \n",
    "                        filter_value = float(filter_value) if '.' in filter_value else int(filter_value)\n",
    "                    \n",
    "                    # Apply filtering based on user's choice\n",
    "                    if filter_type == \"1\":\n",
    "                        df = df[df[col_name] == filter_value]\n",
    "                    elif filter_type == \"2\":\n",
    "                        df = df[df[col_name] > filter_value]\n",
    "                    elif filter_type == \"3\":\n",
    "                        df = df[df[col_name] < filter_value]\n",
    "                    else:\n",
    "                        print(\"Invalid filter choice!\")\n",
    "\n",
    "                    print(\"\\nData filtered successfully!\")\n",
    "\n",
    "                except ValueError:\n",
    "                    print(\"Error: Filter value type does not match column type!\")\n",
    "        elif choice == \"9\":\n",
    "            print(\"\\nRemoving duplicates:\")\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            print(\"\\nDuplicates removed successfully!\")\n",
    "        elif choice == \"10\":\n",
    "            ch=input('Do you want to save this Edited File ?')\n",
    "            if(ch.lower()=='y'):\n",
    "                \n",
    "                save_dataset(df)\n",
    "            b = False\n",
    "        else:\n",
    "            print(\"Please Enter a Valid Choice!\")\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    b=True\n",
    "    while(b):\n",
    "        print(\"DataVista\".center(60, \"=\"))\n",
    "        print(\"1. Analyze Data\")\n",
    "        print(\"2. Edit Data\")\n",
    "        # print(\"3. Cleaning Data\")\n",
    "        # print(\"4. Sort Folder\")\n",
    "        print(\"3. Exit\")\n",
    "        sys.stdout.flush()\n",
    "        choice=input(\"Enter Choice: \")\n",
    "        if(choice==\"1\"):\n",
    "            df = Load_Data()\n",
    "            Analyze_Data(df)\n",
    "        elif(choice==\"2\"):\n",
    "            df = Load_Data()\n",
    "            Edit_Data(df)\n",
    "            pass\n",
    "        elif(choice==\"3\"):\n",
    "            print(\"Exiting Program...\")\n",
    "            b=False      \n",
    "        else:\n",
    "            print(\"Please Enter Valid Choice !\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# main()\n",
    "if __name__=='__main__':\n",
    "    b1=True\n",
    "\n",
    "    while b1:\n",
    "        print(\"Log In/Sign Up\".center(60, \"*\"))\n",
    "        print(\"1. Log In\")\n",
    "        print(\"2. Sign Up\")\n",
    "        print(\"3. Exit\")\n",
    "        sys.stdout.flush()\n",
    "        choice=input()\n",
    "        if choice=='1':\n",
    "            print(\"hello 11111111111111\")\n",
    "            con=get_connection()\n",
    "            cur=con.cursor()\n",
    "            print('email: ')\n",
    "            email=input('Enter Email: ')\n",
    "            print(\"email 1111\")\n",
    "            password=input('Enter Password: ')\n",
    "            print(\"pass\")\n",
    "            encr=hashlib.sha256(password.encode()).hexdigest()\n",
    "            sql= 'select * from users where user_email=%s and user_password=%s'\n",
    "            cur.execute(sql, (email,encr,))\n",
    "            op=cur.fetchone()\n",
    "            if not op:\n",
    "                print('User Not found with the given credentials !')\n",
    "            else:\n",
    "                u=User(op[1], email, password, 0)\n",
    "                u.setId(op[0])\n",
    "                # print(\"*\"*)\n",
    "                print(\"Welcome Back\".center(60, \"*\"))\n",
    "               \n",
    "                sys.stdout.flush()\n",
    "                main()\n",
    "                \n",
    "\n",
    "        elif choice=='2':\n",
    "            name=input('Enter Name: ')\n",
    "            em=True\n",
    "            while(em):\n",
    "                email=input('Enter Email: ')\n",
    "                if email.find('@gmail.com')!=-1:\n",
    "                    em=False\n",
    "                else:\n",
    "                    print('Email must contain \"@gmail.com\" !')\n",
    "            passw=input('Enter Password: ')\n",
    "            con=get_connection()\n",
    "            cur=con.cursor()\n",
    "            sql= 'select * from users where user_email=%s'\n",
    "            cur.execute(sql, (email,))\n",
    "            op=cur.fetchone()\n",
    "            if not op:\n",
    "               u=User(name, email, passw, 1)\n",
    "               \n",
    "               sys.stdout.flush()\n",
    "               main()\n",
    "            else:\n",
    "                print('User already exists !')\n",
    "\n",
    "        else:\n",
    "            b1=False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\archive (3)\\\\covid_toy.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\Diwali Sales Data.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\Diwali Sales Data_Udated.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\Diwali Sales Data_1.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\road_accident_dataset.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\road_accident_dataset_1.csv\n",
    "# D:\\\\shivam\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

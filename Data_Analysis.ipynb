{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import os\n",
    "import textwrap\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Genreal_Report(corr_matrix, dup, head, tail, des, null, info, shape):\n",
    "   \n",
    "     try:\n",
    "        folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        report = os.path.join(folder_path, \"report.txt\")\n",
    "        heatmap_file = os.path.join(folder_path, \"correlation_heatmap.png\")\n",
    "       \n",
    "\n",
    "        rows, cols = corr_matrix.shape\n",
    "        max_label_length = max(len(label) for label in corr_matrix.columns)\n",
    "\n",
    "        fig_width = max(8, cols * 0.5, max_label_length * 0.5)\n",
    "        fig_height = max(6, rows * 0.5)\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(cols), corr_matrix.columns, rotation=45, ha=\"right\", fontsize=12)\n",
    "        plt.yticks(np.arange(rows), corr_matrix.columns, rotation=0, fontsize=12)\n",
    "        plt.title('Correlation Matrix Heatmap', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(heatmap_file)  \n",
    "        plt.close()\n",
    "        with open(report, 'w') as f:\n",
    "            f.write(\"GENERAL ANALYSIS OF THE DATAFRAME\\n\")\n",
    "            f.write(\"*\" * 50 + \"\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(f\"Shape of DataFrame: {shape}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Column Information:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(info + \"\\n\") \n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Missing Values in Each Column:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(null) + \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Descriptive Statistics (Numerical):\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(des) + \"\\n\")\n",
    "            # f.write(tabulate(des, headers='keys', tablefmt='psql'))\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"First 5 Rows of the DataFrame:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(head) + \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Last 5 Rows of the DataFrame:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(tail) + \"\\n\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(f\"Number of Duplicate Rows: {dup}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\\n\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(\"Correlation Matrix (Numerical Columns):\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(str(corr_matrix) + \"\\n\")\n",
    "            f.write(\"\\n\\n\")\n",
    "        \n",
    "        print(f\"Report successfully saved as '{report}'.\")\n",
    "     except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def General_Analysis(df):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERAL ANALYSIS OF THE DATAFRAME\".center(60))\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 200)\n",
    "    shape = df.shape\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Shape of DataFrame: {shape}\")\n",
    "    print(\"-\" * 60 + \"\\n\")\n",
    "    print(\"COLUMN INFORMATION\".center(60, \"-\"))\n",
    "    buffer = StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info = buffer.getvalue()\n",
    "    print(info)\n",
    "    print(\"\\n\")\n",
    "    print(\"MISSING VALUES IN EACH COLUMN\".center(60, \"-\"))\n",
    "    null_values = df.isnull().sum()\n",
    "    print(null_values)\n",
    "    print(\"\\n\")\n",
    "    numdf = df.select_dtypes(include=['number']).fillna(0)\n",
    "    print(\"DESCRIPTIVE STATISTICS (NUMERICAL)\".center(60, \"-\"))\n",
    "    des = numdf.describe()\n",
    "    print(tabulate(des, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"FIRST 5 ROWS OF THE DATAFRAME\".center(60, \"-\"))\n",
    "    head = df.head()\n",
    "    print(tabulate(head, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"LAST 5 ROWS OF THE DATAFRAME\".center(60, \"-\"))\n",
    "    tail = df.tail()\n",
    "    print(tabulate(tail, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    print(\"DUPLICATE ROWS\".center(60, \"-\"))\n",
    "    dup = df.duplicated().sum()\n",
    "    print(f\"Number of Duplicate Rows: {dup}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"CORRELATION MATRIX (NUMERICAL COLUMNS)\".center(60, \"-\"))\n",
    "    corr_matrix = numdf.corr()\n",
    "    print(tabulate(corr_matrix, headers='keys', tablefmt='psql'))\n",
    "    print(\"\\n\")\n",
    "    rows, cols = corr_matrix.shape\n",
    "    max_label_length = max(len(label) for label in corr_matrix.columns)\n",
    "    fig_width = max(8, cols * 0.5, max_label_length * 0.5)\n",
    "    fig_height = max(6, rows * 0.5)\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(cols), corr_matrix.columns, rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(np.arange(rows), corr_matrix.columns, rotation=0, fontsize=12)\n",
    "    plt.title('Correlation Matrix Heatmap', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    save = input('Save General Report? (Y/N): ')\n",
    "    if save.lower()==\"y\":\n",
    "        Save_Genreal_Report(corr_matrix, dup, head, tail, des, null_values, info, shape)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_custom(df, col1, col2):\n",
    "    col_names = {col.lower(): col for col in df.columns}\n",
    "    col1_actual = col_names.get(col1.lower())\n",
    "    col2_actual = col_names.get(col2.lower())\n",
    "\n",
    "    if not col1_actual or not col2_actual:\n",
    "        print(f\"❌ Error: One or both columns '{col1}' or '{col2}' not found in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(df[col1_actual]) or not pd.api.types.is_numeric_dtype(df[col2_actual]):\n",
    "        print(f\"❌ Error: One or both selected columns are not numeric.\")\n",
    "        return\n",
    "\n",
    "    df[col1_actual] = pd.to_numeric(df[col1_actual], errors='coerce')\n",
    "    df[col2_actual] = pd.to_numeric(df[col2_actual], errors='coerce')\n",
    "    df.dropna(inplace=True)  \n",
    "\n",
    "    # Generate report text\n",
    "    report_lines = [\n",
    "        \"=============================== Preview ================================\\n\",\n",
    "        f\"Data for {col1_actual}:\\n{tabulate(df[col1_actual].head().to_frame(), headers='keys', tablefmt='psql')}\\n\",\n",
    "        f\"Data for {col2_actual}:\\n{tabulate(df[col2_actual].head().to_frame(), headers='keys', tablefmt='psql')}\\n\",\n",
    "        f\"================================ Summary Statistics for {col1_actual} ======================================\\n\",\n",
    "        tabulate(df[col1_actual].describe().to_frame().reset_index(), headers=['Statistic', col1_actual], tablefmt='psql') + \"\\n\",\n",
    "        f\"================================ Summary Statistics for {col2_actual} ======================================\\n\",\n",
    "        tabulate(df[col2_actual].describe().to_frame().reset_index(), headers=['Statistic', col2_actual], tablefmt='psql') + \"\\n\",\n",
    "        f\"Correlation between {col1_actual} and {col2_actual}: {df[col1_actual].corr(df[col2_actual])}\\n\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "    jitter_x = np.random.normal(0, (df[col1_actual].max() - df[col1_actual].min()) * 0.02, size=len(df[col1_actual]))\n",
    "    jitter_y = np.random.normal(0, (df[col2_actual].max() - df[col2_actual].min()) * 0.02, size=len(df[col2_actual]))\n",
    "\n",
    "    plt.scatter(df[col1_actual] + jitter_x, df[col2_actual] + jitter_y, alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Scatter Plot with Jitter\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(df.index, df[col2_actual].rolling(window=500, min_periods=1).mean(), linestyle='-')\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Line Plot\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(df[col1_actual], bins=30, alpha=0.7, density=True, color='blue', label=col1_actual)\n",
    "    plt.hist(df[col2_actual], bins=30, alpha=0.7, density=True, color='red', label=col2_actual)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Histogram\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(df[[col1_actual, col2_actual]].corr(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.yticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    new_folder_path = os.path.join(folder_path, \"report.txt\")\n",
    "   \n",
    "    \n",
    "    \n",
    "    with open(new_folder_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(report_lines)\n",
    "\n",
    "    visualization_file = os.path.join(folder_path, \"visualization.png\")\n",
    "    plt.savefig(visualization_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Report saved at: {new_folder_path}\")\n",
    "    print(f\"✅ Visualization saved at: {visualization_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_Analysis(df, col1, col2, num):\n",
    "    col_names = {col.lower(): col for col in df.columns}\n",
    "    col1_actual = col_names.get(col1.lower())\n",
    "    col2_actual = col_names.get(col2.lower())\n",
    "    if not col1_actual or not col2_actual:\n",
    "        print(f\"❌ Error: One or both columns '{col1}' or '{col2}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[col1_actual]):\n",
    "        print(f\"❌ Error: Column '{col1_actual}' is not numeric.\")\n",
    "        return\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[col2_actual]):\n",
    "        print(f\"❌ Error: Column '{col2_actual}' is not numeric.\")\n",
    "        return\n",
    "    \n",
    "    if(df[col1].isna().all() or (df[col1]==\"\").all()):\n",
    "        print(f'column {col1} is completely Empty !')\n",
    "        return\n",
    "    if(df[col2].isna().all() or (df[col2]==\"\").all()):\n",
    "        print(f'column {col2} is completely Empty !')\n",
    "\n",
    "    print(df[col1_actual], \"hello -1\")\n",
    "    print(df[col2_actual], \"hello 0\")\n",
    "    df[col1_actual] = pd.to_numeric(df[col1_actual], errors='coerce')\n",
    "    df[col2_actual] = pd.to_numeric(df[col2_actual], errors='coerce')\n",
    "    \n",
    "    # this wont work in diwali sales cause status and unamed are totally empty so it will delete all rows\n",
    "    # df.dropna(inplace=True)  \n",
    "    \n",
    "    column1_data = df[col1_actual]\n",
    "    column2_data = df[col2_actual]\n",
    "    print(df[col1_actual], \"hello 0.25\")\n",
    "    print(df[col2_actual], \"hello 0.35\")\n",
    "    print(column1_data, \"hello 0.5\")\n",
    "    print(column2_data, \"hello 0.75\")\n",
    "    \n",
    "\n",
    "    print(\"=============================== Preview ================================\")\n",
    "    column1_data_df = column1_data.head().to_frame()\n",
    "    column2_data_df = column2_data.head().to_frame()\n",
    "    print(column1_data_df, \"hello 1\")\n",
    "    print(column2_data_df, \"hello 2\")\n",
    "    print(f\"Data for {col1_actual}:\\n\", tabulate(column1_data_df, headers='keys', tablefmt='psql'), \"\\n\")\n",
    "    print(f\"Data for {col2_actual}:\\n\", tabulate(column2_data_df, headers='keys', tablefmt='psql'), \"\\n\")\n",
    "    print(f\"================================ Summary Statistics for {col1_actual} ======================================\")\n",
    "    column1_stats = column1_data.describe()\n",
    "\n",
    "    column1_stats_df = column1_stats.to_frame().reset_index()\n",
    "    print(tabulate(column1_stats_df, headers=['Statistic', col1_actual], tablefmt='psql'), \"\\n\")\n",
    "    \n",
    "    print(f\"====================================== Summary Statistics for {col2_actual} ========================================\")\n",
    "    column2_stats = column2_data.describe()\n",
    "\n",
    "    column2_stats_df = column2_stats.to_frame().reset_index()\n",
    "    print(tabulate(column2_stats_df, headers=['Statistic', col2_actual], tablefmt='psql'), \"\\n\")\n",
    "    # print(column2_data.describe(), \"\\n\")\n",
    "    null_count_col1 = column1_data.isnull().sum()\n",
    "    empty_count_col1 = (column1_data.eq('')).sum()\n",
    "    null_count_col2 = column2_data.isnull().sum()\n",
    "    empty_count_col2 = (column2_data.eq('')).sum()\n",
    "    print(f\"Null values in {col1_actual}: {null_count_col1}\")\n",
    "    print(f\"Empty values in {col1_actual}: {empty_count_col1}\\n\")\n",
    "    \n",
    "    print(f\"Null values in {col2_actual}: {null_count_col2}\")\n",
    "    print(f\"Empty values in {col2_actual}: {empty_count_col2}\\n\")\n",
    "    correlation = column1_data.corr(column2_data)\n",
    "    print(f\"Correlation between {col1_actual} and {col2_actual}: {correlation}\\n\")\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "   \n",
    "    \n",
    "   \n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "\n",
    "\n",
    "    jitter_x = np.random.normal(0, (df[col1_actual].max() - df[col1_actual].min()) * 0.02, size=len(df[col1_actual]))\n",
    "    jitter_y = np.random.normal(0, (df[col2_actual].max() - df[col2_actual].min()) * 0.02, size=len(df[col2_actual]))\n",
    "\n",
    "    plt.scatter(df[col1_actual] + jitter_x, df[col2_actual] + jitter_y, alpha=0.4, edgecolor='k', linewidth=0.5)\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(\"Scatter Plot with Jitter\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "\n",
    "    rolling_window = 500  \n",
    "    df['RollingMean'] = df[col2_actual].rolling(window=rolling_window, min_periods=1).mean()\n",
    "\n",
    "    plt.plot(df.index, df['RollingMean'], linestyle='-')\n",
    "\n",
    "    plt.xlabel(col1_actual)\n",
    "    plt.ylabel(col2_actual)\n",
    "    plt.title(f\"Line Plot (Smoothed, Window={rolling_window})\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)  \n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(df[col1_actual], bins=30, alpha=0.7, density=True, color='darkblue', label=col1_actual)  \n",
    "    plt.hist(df[col2_actual], bins=30, alpha=0.7, density=True, color='darkred', label=col2_actual)  \n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Histogram (Optimized)\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    corr_matrix = df[[col1_actual, col2_actual]].corr()\n",
    "    plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], [col1_actual, col2_actual], rotation=45)\n",
    "    plt.yticks([0, 1], [col1_actual, col2_actual])\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    save=input(\"Do you want to save this report ?\")\n",
    "    if(save.lower()==\"y\"):\n",
    "        save_custom(df, col1, col2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_string_report(df, column_name, output_folder=\"output\", top_n=10):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    # os.makedirs(output_folder, exist_ok=True)  \n",
    "    # report_path = os.path.join(output_folder, f\"{column_name}_report.txt\")  \n",
    "    # img_path = os.path.join(output_folder, f\"{column_name}_visualization.png\")  \n",
    "\n",
    "    \n",
    "    value_counts = Counter(df[column_name].dropna())\n",
    "\n",
    "    if len(value_counts) > top_n:\n",
    "        most_common = dict(value_counts.most_common(top_n))\n",
    "        others_count = sum(count for key, count in value_counts.items() if key not in most_common)\n",
    "        most_common[\"Others\"] = others_count\n",
    "        value_counts = most_common\n",
    "\n",
    "    labels = list(value_counts.keys())\n",
    "    counts = list(value_counts.values())\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(labels, counts, color='darkblue')\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {column_name} (Top {top_n} Categories)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors)\n",
    "    plt.title(f\"Distribution of {column_name} (Pie Chart)\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    text = \" \".join(df[column_name].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Word Cloud for {column_name}\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    heatmap_data = np.array(counts).reshape(1, -1)\n",
    "    plt.imshow(heatmap_data, aspect='auto', cmap='Blues')\n",
    "    plt.colorbar(label=\"Count\")\n",
    "    plt.title(f\"Heatmap for {column_name}\")\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels, rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(img_path)  \n",
    "    \n",
    "\n",
    "\n",
    "    folder_path = input(\"Enter the full path or name of the folder to save the report and heatmap: \").strip()\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    new_folder_path = os.path.join(folder_path, \"report.txt\")\n",
    "\n",
    "    with open(new_folder_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Report for Column: {column_name}\\n\")\n",
    "        file.write(\"=\" * 40 + \"\\n\\n\")\n",
    "        file.write(f\"Total Unique Values: {len(value_counts)}\\n\")\n",
    "        file.write(\"\\nTop Occurring Values:\\n\")\n",
    "\n",
    "        for label, count in zip(labels, counts):\n",
    "            file.write(f\"{label}: {count}\\n\")\n",
    "\n",
    "        # file.write(\"\\nVisualization saved at: \" + img_path + \"\\n\")\n",
    "    visualization_file = os.path.join(folder_path, \"visualization.png\")\n",
    "    plt.savefig(visualization_file)\n",
    "    plt.close()\n",
    "    print(f\"Report saved: {new_folder_path}\")\n",
    "    print(f\"Visualization saved: {visualization_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_string_column(df, column_name, top_n=10):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    value_counts = Counter(df[column_name].dropna())  \n",
    "\n",
    "    if len(value_counts) > top_n:\n",
    "        most_common = dict(value_counts.most_common(top_n))\n",
    "        others_count = sum(count for _, count in value_counts.items() if _ not in most_common)\n",
    "        most_common[\"Others\"] = others_count\n",
    "        \n",
    "        value_counts = most_common\n",
    "\n",
    "    labels = list(value_counts.keys())\n",
    "    counts = list(value_counts.values())\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)  \n",
    "    plt.bar(labels, counts, color='darkblue')\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {column_name} (Top {top_n} Categories)\")\n",
    "\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    plt.subplot(2, 2, 2)  \n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors)\n",
    "    plt.title(f\"Distribution of {column_name} (Pie Chart)\")\n",
    "\n",
    "    \n",
    "    plt.subplot(2, 2, 3)  \n",
    "    if df[column_name].dtype == 'object':  \n",
    "        text = \" \".join(df[column_name].dropna())\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Word Cloud for {column_name}\")\n",
    "    else:\n",
    "        plt.axis('off')  \n",
    "    plt.subplot(2, 2, 4) \n",
    "   \n",
    "    heatmap_data = np.array(counts).reshape(1, -1) \n",
    "    plt.imshow(heatmap_data, aspect='auto', cmap='Blues')\n",
    "    plt.colorbar(label=\"Count\")\n",
    "    plt.title(f\"Heatmap for {column_name}\")\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels, rotation=90)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Basic Analysis\n",
    "    print(f\"\\n====================================== Basic Analysis of '{column_name}' ===========================================\")\n",
    "    print(f\"Total unique values (Top {top_n} with 'Others'): {len(value_counts)}\")\n",
    "    for label, count in value_counts.items():\n",
    "        print(f\"{label}: {count} occurrences\")\n",
    "    choice=input(\"want to save this repiort (y/n) ?\")\n",
    "    if(choice.lower()=='y'):\n",
    "        save_string_report(df, column_name, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Data(df):\n",
    "    b=True\n",
    "    while(b):\n",
    "        print(\"1. General Analysis\")\n",
    "        print(\"2. Custom Analysis\")\n",
    "        print(\"3. Return\")\n",
    "        choice=input(\"Enter Choice: \").strip()\n",
    "        if(choice==\"1\"):\n",
    "           General_Analysis(df)\n",
    "        elif(choice==\"2\"):\n",
    "            b1=True\n",
    "            while(b1):\n",
    "                print(\"1. Analyze Two Numeric Columns\")\n",
    "                print(\"2. Analyze String Column\")\n",
    "                print(\"3. Return\")\n",
    "                choice=input(\"Enter Choice: \").strip()\n",
    "                if(choice==\"1\"):\n",
    "                  col1=input('Enter 1st Numeric Column')\n",
    "                  col2=input('Enter 2nd Numeric Column')\n",
    "                  Custom_Analysis(df, col1, col2, 1)\n",
    "                  \n",
    "                elif(choice==\"2\"):\n",
    "                    # col1=input('Enter 1st Numeric Column')\n",
    "                    col2=input('Enter String Column')\n",
    "                    plot_string_column(df, col2)\n",
    "                elif(choice==\"3\"):\n",
    "                  b1=False\n",
    "                else:\n",
    "                  print(\"Please Enter Valid Choice !\")\n",
    "        elif(choice==\"3\"):\n",
    "          # print(\"Exiting Program...\")\n",
    "          b=False\n",
    "        else:\n",
    "          print(\"Please Enter Valid Choice !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Data():\n",
    "    b=True\n",
    "    while(b):\n",
    "        print(\"1. Analyze CSV File\")\n",
    "        print(\"2. Analyze Parquet File\")\n",
    "        print(\"3. Analyze Excel File\")\n",
    "        print(\"4. Return\")\n",
    "        choice=input(\"Enter Choice: \").strip()\n",
    "        if(choice==\"1\"):\n",
    "          path = input(\"Enter File Path of CSV File: \")\n",
    "          try:\n",
    "              df = pd.read_csv(path, encoding='unicode_escape')\n",
    "              return df\n",
    "          except (FileNotFoundError, Exception) as e:\n",
    "              print(f\"Error: {e}\")\n",
    "            #   print(\"CSV File not found. Try again !\")\n",
    "               \n",
    "        elif(choice==\"2\"):\n",
    "              path = input(\"Enter File Path of Parquet File: \")\n",
    "              try:\n",
    "                  df = pd.read_parquet(path)\n",
    "                  return df\n",
    "              except (FileNotFoundError, Exception) as e:\n",
    "                  print(f\"Error: {e}\")\n",
    "                  print(\"Parquet File not found. Try again !\")\n",
    "        elif(choice==\"3\"):\n",
    "              path = input(\"Enter File Path of Excel File: \")\n",
    "              try:\n",
    "                  df = pd.read_excel(path)\n",
    "                  return df\n",
    "              except (FileNotFoundError, Exception) as e:\n",
    "                  print(f\"Error: {e}\")\n",
    "                  print(\"Excel File not found. Try again !\")\n",
    "        elif(choice==\"4\"):\n",
    "          # print(\"Exiting Program...\")\n",
    "          b=False\n",
    "        else:\n",
    "          print(\"Please Enter Valid Choice !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(df):\n",
    "    \"\"\"Saves the dataset to a user-specified path.\"\"\"\n",
    "    save_path = input(\"Enter the path to save the edited CSV file: \")\n",
    "    try:\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nDataset saved successfully at {save_path}!\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edit_Data(df):\n",
    "    b = True\n",
    "    while b:\n",
    "        print(\"1. Add a New Row\")\n",
    "        print(\"2. Update an Existing Row\")\n",
    "        print(\"3. Delete a Row\")\n",
    "        print(\"4. Edit Specific Column Data\")\n",
    "        print(\"5. Fill Missing Data\")\n",
    "        print(\"6. Rename Columns\")\n",
    "        print(\"7. Change Data Type of a Column\")\n",
    "        print(\"8. Sort Data\")\n",
    "        print(\"9. Filter Data\")\n",
    "        print(\"10. Remove Duplicates\")\n",
    "        print(\"11. Return\")\n",
    "        \n",
    "        choice = input(\"Enter Choice: \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            print(\"\\nAdding a new row:\")\n",
    "            new_row = {}\n",
    "            for col in df.columns:\n",
    "                new_row[col] = input(f\"Enter value for {col}: \")\n",
    "            df.loc[len(df)] = new_row \n",
    "            print(\"\\nRow added successfully!\")\n",
    "        elif choice == \"2\":\n",
    "            print(\"\\nUpdating an existing row:\")\n",
    "            row_index = int(input(\"Enter row index to update: \"))\n",
    "            if 0 <= row_index < len(df):\n",
    "                col_name = input(\"Enter column name to update: \")\n",
    "                new_value = input(\"Enter new value: \")\n",
    "                df.at[row_index, col_name] = new_value\n",
    "                print(\"\\nRow updated successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid row index!\")\n",
    "        elif choice == \"3\":\n",
    "            print(\"\\nDeleting a row:\")\n",
    "            row_index = int(input(\"Enter row index to delete: \"))\n",
    "            if 0 <= row_index < len(df):\n",
    "                df = df.drop(index=row_index).reset_index(drop=True)\n",
    "                print(\"\\nRow deleted successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid row index!\")\n",
    "        elif choice == \"4\":\n",
    "            print(\"\\nEditing specific column data:\")\n",
    "            col_name = input(\"Enter column name: \")\n",
    "            if col_name in df.columns:\n",
    "                df[col_name] = df[col_name].apply(lambda x: input(f\"Enter new value for {x}: \"))\n",
    "                print(\"\\nColumn updated successfully!\")\n",
    "            else:\n",
    "                print(\"\\nInvalid column name!\")\n",
    "        elif choice == \"5\":\n",
    "            print(\"\\nFilling missing data:\")\n",
    "            fill_method = input(\"Enter 'mean', 'median', 'mode', or a specific value: \")\n",
    "            if fill_method == \"mean\":\n",
    "                df.fillna(df.mean(), inplace=True)\n",
    "            elif fill_method == \"median\":\n",
    "                df.fillna(df.median(), inplace=True)\n",
    "            elif fill_method == \"mode\":\n",
    "                df.fillna(df.mode().iloc[0], inplace=True)\n",
    "            else:\n",
    "                df.fillna(fill_method, inplace=True)\n",
    "            print(\"\\nMissing values filled successfully!\")\n",
    "        elif choice == \"6\":\n",
    "            print(\"\\nRenaming columns:\")\n",
    "            print(\"Current columns:\", list(df.columns))\n",
    "            old_col = input(\"Enter the column name to rename: \")\n",
    "            new_col = input(\"Enter the new column name: \")\n",
    "            df.rename(columns={old_col: new_col}, inplace=True)\n",
    "            print(\"\\nColumn renamed successfully!\")\n",
    "        elif choice == \"7\":\n",
    "            print(\"\\nChanging data type of a column:\")\n",
    "            col_name = input(\"Enter column name: \")\n",
    "            new_type = input(\"Enter new data type (int, float, str): \")\n",
    "            try:\n",
    "                if new_type == \"int\":\n",
    "                    df[col_name] = df[col_name].astype(int)\n",
    "                elif new_type == \"float\":\n",
    "                    df[col_name] = df[col_name].astype(float)\n",
    "                elif new_type == \"str\":\n",
    "                    df[col_name] = df[col_name].astype(str)\n",
    "                print(\"\\nData type changed successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error changing data type: {e}\")\n",
    "        elif choice == \"8\":\n",
    "            print(\"\\nSorting data:\")\n",
    "            col_name = input(\"Enter column name to sort by: \")\n",
    "            order = input(\"Enter 'asc' for ascending or 'desc' for descending: \")\n",
    "            df = df.sort_values(by=col_name, ascending=(order == \"asc\"))\n",
    "            print(\"\\nData sorted successfully!\")\n",
    "        elif choice == \"9\":\n",
    "           print(\"\\nFiltering data:\")\n",
    "           col_name = input(\"Enter column name to filter by: \")\n",
    "\n",
    "            # Check if column exists\n",
    "           if col_name not in df.columns:\n",
    "                print(\"Error: Column does not exist!\")\n",
    "           else:\n",
    "                print(\"\\nChoose filter type:\")\n",
    "                print(\"1. Equal to (==)\")\n",
    "                print(\"2. Greater than (>)\")\n",
    "                print(\"3. Smaller than (<)\")\n",
    "                filter_type = input(\"Enter choice (1/2/3): \")\n",
    "\n",
    "                filter_value = input(f\"Enter value to filter {col_name} by: \")\n",
    "\n",
    "                try:\n",
    "                    # Convert filter_value to correct type (int/float if possible)\n",
    "                    if df[col_name].dtype in ['int64', 'float64']:  \n",
    "                        filter_value = float(filter_value) if '.' in filter_value else int(filter_value)\n",
    "                    \n",
    "                    # Apply filtering based on user's choice\n",
    "                    if filter_type == \"1\":\n",
    "                        df = df[df[col_name] == filter_value]\n",
    "                    elif filter_type == \"2\":\n",
    "                        df = df[df[col_name] > filter_value]\n",
    "                    elif filter_type == \"3\":\n",
    "                        df = df[df[col_name] < filter_value]\n",
    "                    else:\n",
    "                        print(\"Invalid filter choice!\")\n",
    "\n",
    "                    print(\"\\nData filtered successfully!\")\n",
    "\n",
    "                except ValueError:\n",
    "                    print(\"Error: Filter value type does not match column type!\")\n",
    "        elif choice == \"10\":\n",
    "            print(\"\\nRemoving duplicates:\")\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            print(\"\\nDuplicates removed successfully!\")\n",
    "        elif choice == \"11\":\n",
    "            save_dataset(df)\n",
    "            b = False\n",
    "        else:\n",
    "            print(\"Please Enter a Valid Choice!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=True\n",
    "while(b):\n",
    "    print(\"1. Analyze Data\")\n",
    "    print(\"2. Edit Data\")\n",
    "    print(\"3. Cleaning Data\")\n",
    "    print(\"4. Sort Folder\")\n",
    "    print(\"5. Exit\")\n",
    "    choice=input(\"Enter Choice: \")\n",
    "    if(choice==\"1\"):\n",
    "        df = Load_Data()\n",
    "        Analyze_Data(df)\n",
    "    elif(choice==\"2\"):\n",
    "        df = Load_Data()\n",
    "        Edit_Data(df)\n",
    "        pass\n",
    "    elif(choice==\"3\"):\n",
    "        print(3)\n",
    "        pass\n",
    "    elif(choice==\"4\"):\n",
    "        print(4)\n",
    "    elif(choice==\"5\"):\n",
    "          print(\"Exiting Program...\")\n",
    "          b=False\n",
    "    else:\n",
    "        print(\"Please Enter Valid Choice !\")\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\Diwali Sales Data.csv\n",
    "# C:\\\\Users\\\\Shivam\\\\Downloads\\\\road_accident_dataset.csv\n",
    "# D:\\\\shivam\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
